{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_hierarchical.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3pCspYexjnNa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment Classification"
      ]
    },
    {
      "metadata": {
        "id": "pgNKwMkzjnNe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "metadata": {
        "id": "s3U-X848y6Fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7aOQKkauWuB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BuKpuECYWxuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdUU8fIcW0JL",
        "colab_type": "code",
        "outputId": "dde3f85f-e596-4535-c6a6-8156c69ca380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wJx76Gu0W2mm",
        "colab_type": "code",
        "outputId": "a1584f44-8b01-42fd-b434-5edc8d523c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "coxeyvnWW4vE",
        "colab_type": "code",
        "outputId": "471a00e8-b607-4062-93c3-9b971e796896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TNwVU54QW7OK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Embedding, GRU, Bidirectional, Layer, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rOkgkiWnW9VD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owI6_lKoUKN9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Trained Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "IQRUhUgtNiEL",
        "colab_type": "code",
        "outputId": "e04cab53-25e7-499f-a598-6b56bb63fdf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-17 03:02:34--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-03-17 03:02:34--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  7.32MB/s    in 98s     \n",
            "\n",
            "2019-03-17 03:04:13 (8.42 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AONqUS9DUWWh",
        "colab_type": "code",
        "outputId": "0484e698-018c-44a4-97fb-ea51d86b20ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jNi9Ru7fOJhM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open(\"glove.6B.300d.txt\", \"r\") as embeddings_file:\n",
        "    for embedding_line in embeddings_file:\n",
        "        embedding = embedding_line.split(\" \")\n",
        "        word = embedding[0]\n",
        "        embeddings_index[word] = np.asarray(embedding[1:], dtype=\"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2f_3dtBvjnOr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Main Function"
      ]
    },
    {
      "metadata": {
        "id": "GwSTVA8hjnOy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "WlyR0sLIjnO2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_words = 20000\n",
        "max_words_per_sentence = 20\n",
        "max_sentences_per_doc = 20\n",
        "embedding_size = 300\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "total_epoch = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oqo0u_zMXeK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "RfGMiRPyZRwn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDurB9VLXi5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_text(data, max_words, max_words_per_sentence, max_sentences_per_doc, tokenizer=None):\n",
        "    words = data\n",
        "    \n",
        "    words = words.apply(lambda doc: doc.lower().strip())\n",
        "    words = words.apply(lambda doc: re.sub(r\"([?.!,¿])\", r\" \\1 \", doc))\n",
        "    words = words.apply(lambda doc: re.sub(r'[\" \"]+', \" \", doc))\n",
        "    words = words.apply(lambda doc: re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", doc))\n",
        "    words = words.apply(lambda doc: doc.rstrip().strip())\n",
        "    \n",
        "    words = words.apply(lambda doc: doc.split(\" \"))\n",
        "    words = words.apply(lambda doc: [word for word in doc if word not in stop_words])\n",
        "    words = words.apply(lambda doc: \" \".join(doc))\n",
        "    \n",
        "    if tokenizer is None:\n",
        "        tokenizer = Tokenizer(num_words=max_words, oov_token=\"<UNK>\")\n",
        "        tokenizer.fit_on_texts(words)\n",
        "    \n",
        "    words = words.apply(lambda doc: sent_tokenize(doc))\n",
        "    words = pad_sequences(\n",
        "        words,\n",
        "        maxlen=max_sentences_per_doc,\n",
        "        dtype=object,\n",
        "        padding=\"post\",\n",
        "        truncating=\"post\",\n",
        "        value=\"\"\n",
        "    )\n",
        "    \n",
        "    words = np.apply_along_axis(tokenizer.texts_to_sequences, 0, words)\n",
        "    words = np.apply_along_axis(lambda sentences: pad_sequences(\n",
        "        sentences,\n",
        "        maxlen=max_words_per_sentence,\n",
        "        padding=\"post\",\n",
        "        truncating=\"post\"\n",
        "    ), 1, words)\n",
        "    \n",
        "    return words, tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X9YV1slmzT17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the Data"
      ]
    },
    {
      "metadata": {
        "id": "XHJcl0NrzWN-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"data/train.csv\")\n",
        "valid_data = pd.read_csv(\"data/valid.csv\")\n",
        "test_data = pd.read_csv(\"data/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k0OnIx_G0C1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_stars = train_data[\"stars\"].apply(int) - 1\n",
        "train_label = to_categorical(train_stars, num_classes=5)\n",
        "valid_stars = valid_data[\"stars\"].apply(int) - 1\n",
        "valid_label = to_categorical(valid_stars, num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTynTm120Tev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_words, tokenizer = parse_text(train_data[\"text\"], max_words, max_words_per_sentence, max_sentences_per_doc)\n",
        "valid_words, _ = parse_text(valid_data[\"text\"], max_words, max_words_per_sentence, max_sentences_per_doc, tokenizer=tokenizer)\n",
        "test_words, _ = parse_text(test_data[\"text\"], max_words, max_words_per_sentence, max_sentences_per_doc, tokenizer=tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Y3I1UTIP97f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_weights = np.zeros((len(tokenizer.word_index) + 1, embedding_size))\n",
        "for word, word_id in tokenizer.word_index.items():\n",
        "    embedding = embeddings_index.get(word)\n",
        "    if embedding is not None:\n",
        "        embedding_weights[word_id] = embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E43UFzs5_zwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Attention Layer"
      ]
    },
    {
      "metadata": {
        "id": "ArGXijQE_1eE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Attention(Layer):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.context_vector = self.add_weight(\n",
        "            name=\"context_vector\",\n",
        "            shape=(input_shape[1][2], 1),\n",
        "            initializer=\"uniform\",\n",
        "            trainable=True\n",
        "        )\n",
        "        super(Attention, self).build(input_shape)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        gru, hidden_hidden = inputs\n",
        "        \n",
        "        attention = K.dot(hidden_hidden, self.context_vector)\n",
        "        \n",
        "        attention = K.softmax(attention, axis=1)\n",
        "        \n",
        "        return K.sum(attention * gru, axis=1)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0], input_shape[0][2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-qbKh43njnPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "R6YYdhCYikVA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_sentences_per_doc, max_words_per_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aq_qurGK68J5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words_input = Input(shape=(max_words_per_sentence, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILVecGjg7g0f",
        "colab_type": "code",
        "outputId": "72ff7e1b-022e-4902-a3d9-76c5a3e95384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings = Embedding(\n",
        "    len(tokenizer.word_index) + 1,\n",
        "    embedding_size,\n",
        "    input_length=max_words_per_sentence,\n",
        "    weights=[embedding_weights],\n",
        "    trainable=False\n",
        ")(words_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8I98-LXY96_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gru = Bidirectional(GRU(\n",
        "    50,\n",
        "    activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\",\n",
        "    return_sequences=True\n",
        "))(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a48eTATUSPJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_hidden = Dense(100, activation=\"tanh\")(gru)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8fpu5B2DxUS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "attention_layer = Attention()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wz4ktvD_D53W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "attention_output = attention_layer([gru, hidden_hidden])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGXtXuTliLIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words_attention_model = Model(inputs=words_input, outputs=attention_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MeALA06oiTob",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_embeddings = TimeDistributed(words_attention_model)(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhKA4Ou_isXs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_gru = Bidirectional(GRU(\n",
        "    50,\n",
        "    activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\",\n",
        "    return_sequences=True\n",
        "))(sentence_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RnDoh0mcizx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_hidden_hidden = Dense(100, activation=\"tanh\")(sentence_gru)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYHzYr11i42_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_attention_layer = Attention()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUxzY8ZYi7cR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_attention_output = sentence_attention_layer([sentence_gru, sentence_hidden_hidden])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpM8__uiXez7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentiment = Dense(5, activation=\"softmax\")(sentence_attention_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0Wh34d5XMQa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inputs, outputs=sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZ1cTTJnZR6c",
        "colab_type": "code",
        "outputId": "c90c98ae-984d-47cc-ec69-8528cb41df2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "cell_type": "code",
      "source": [
        "words_attention_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 300)      23076000    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 20, 100)      105300      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 100)      10100       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_1 (Attention)         (None, 100)          100         bidirectional_1[0][0]            \n",
            "                                                                 dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,191,500\n",
            "Trainable params: 115,500\n",
            "Non-trainable params: 23,076,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gWt2E6sJZWvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, \"words_attention_model.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cT_kANRbPKsq",
        "colab_type": "code",
        "outputId": "ca58e6ca-aea8-4c55-9826-92b265d7d12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 20, 20)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 20, 100)      23191500    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 20, 100)      45300       time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20, 100)      10100       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_2 (Attention)         (None, 100)          100         bidirectional_2[0][0]            \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 5)            505         attention_2[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 23,247,505\n",
            "Trainable params: 171,505\n",
            "Non-trainable params: 23,076,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kw-jFKw_cJy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, \"model.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uL7SankDjnPv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fngQ_U4GjnP1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QA5OJfZjnQC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "k7KhHRk6jnQE",
        "colab_type": "code",
        "outputId": "6602b233-be1b-44f8-8171-ebf1b07427de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_words,\n",
        "    train_label,\n",
        "    epochs=total_epoch,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=1, restore_best_weights=True)],\n",
        "    validation_data=(valid_words, valid_label)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "100000/100000 [==============================] - 137s 1ms/step - loss: 0.9118 - acc: 0.6215 - val_loss: 0.8255 - val_acc: 0.6510\n",
            "Epoch 2/5\n",
            "100000/100000 [==============================] - 134s 1ms/step - loss: 0.8033 - acc: 0.6616 - val_loss: 0.7932 - val_acc: 0.6697\n",
            "Epoch 3/5\n",
            "100000/100000 [==============================] - 134s 1ms/step - loss: 0.7675 - acc: 0.6776 - val_loss: 0.7747 - val_acc: 0.6795\n",
            "Epoch 4/5\n",
            "100000/100000 [==============================] - 134s 1ms/step - loss: 0.7352 - acc: 0.6890 - val_loss: 0.7678 - val_acc: 0.6794\n",
            "Epoch 5/5\n",
            "100000/100000 [==============================] - 134s 1ms/step - loss: 0.7063 - acc: 0.7008 - val_loss: 0.7652 - val_acc: 0.6838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe69c37fc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "G2mdq_hFjnQU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the Model"
      ]
    },
    {
      "metadata": {
        "id": "Xw77cy40jnQY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath = \"model.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sp0q384hjnQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wB07MbZojnQi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ]
    },
    {
      "metadata": {
        "id": "LaDuD_fTjnQj",
        "colab_type": "code",
        "outputId": "9d08bcb7-2194-4cc1-8900-14b6c3ab0d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "train_score = model.evaluate(train_words, train_label, batch_size=batch_size)\n",
        "print('Training Loss: {}\\n Training Accuracy: {}\\n'.format(train_score[0], train_score[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000/100000 [==============================] - 55s 550us/step\n",
            "Training Loss: 0.6621654364776611\n",
            " Training Accuracy: 0.72103\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fLvHJAx9jnQm",
        "colab_type": "code",
        "outputId": "0186dde3-790e-4de5-a127-83ea8ea7d9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "valid_score = model.evaluate(valid_words, valid_label, batch_size=batch_size)\n",
        "print('Validation Loss: {}\\n Validation Accuracy: {}\\n'.format(valid_score[0], valid_score[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 547us/step\n",
            "Validation Loss: 0.7651836580276489\n",
            " Validation Accuracy: 0.6838\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTaKcNuMjnQo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict and Save the Result"
      ]
    },
    {
      "metadata": {
        "id": "MBmuVDv3jnQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_pre = model.predict(test_words, batch_size=batch_size).argmax(axis=-1) + 1\n",
        "sub_df = pd.DataFrame()\n",
        "sub_df[\"review_id\"] = test_data[\"review_id\"]\n",
        "sub_df[\"pre\"] = test_pre\n",
        "sub_df.to_csv(\"pre.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WpyGdzbpsKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}